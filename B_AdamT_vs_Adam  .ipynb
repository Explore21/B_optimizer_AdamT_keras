{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    " #from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Lambda, Multiply,GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "import cv2, numpy as np\n",
    "import glob\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.activations import relu \n",
    "import keras as keras\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import  Input,Conv2D,BatchNormalization,Activation,Lambda,Subtract,concatenate,Add,add,Reshape\n",
    "\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose,DepthwiseConv2D,Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import losses\n",
    "from keras.layers import  Layer,Activation, Lambda, MaxPooling2D, UpSampling2D, Conv2DTranspose, SpatialDropout2D\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping \n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from  sklearn.model_selection import train_test_split\n",
    "\n",
    "#from tensorflow.python import debug as tf_debug\n",
    "import imageio\n",
    "import glob\n",
    "from skimage import transform as tf\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "\n",
    "\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as plt_img\n",
    "import scipy\n",
    "import scipy\n",
    "import skimage\n",
    "import re\n",
    "#import LRFinder\n",
    "import math as m\n",
    "import tensorflow as tf \n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler \n",
    "from keras import backend as K\n",
    "from pathlib import Path\n",
    "from keras import objectives\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    " \n",
    "from keras import backend as K\n",
    "from skimage.measure import compare_ssim, compare_psnr\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "tf.random.Generator = None \n",
    "import tensorflow_addons as tfa\n",
    "from keras.datasets import  mnist, fashion_mnist\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.fftpack import dct, idct\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (X_test, Y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 50000 10000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(y_train),  len(X_test), len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(Y_test)\n",
    "\n",
    "print(y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "image_size = x_train.shape[1]\n",
    "\n",
    "x_train = np.reshape(x_train,[-1, image_size, image_size, 3])\n",
    "X_test = np.reshape(X_test,[-1, image_size, image_size, 3])\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "print(x_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "x_val=X_test[:8000]\n",
    "y_val=Y_test[:8000]\n",
    "x_test=X_test[8001:]\n",
    "y_test=Y_test[8001:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_shape = (image_size, image_size, 3)\n",
    "batch_size = 128\n",
    "kernel_size = 3\n",
    "filters = 64\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(units, dropout=0.2, activation='relu', block=1, layer=1):\n",
    "\n",
    "    def layer_wrapper(inp):\n",
    "        x = Conv2D(units, (3, 3), padding='same', name='block{}_conv{}'.format(block, layer))(inp)\n",
    "        x = BatchNormalization(name='block{}_bn{}'.format(block, layer))(x)\n",
    "        x = Activation(activation, name='block{}_act{}'.format(block, layer))(x)\n",
    "        x = Dropout(dropout, name='block{}_dropout{}'.format(block, layer))(x)\n",
    "        return x\n",
    "\n",
    "    return layer_wrapper\n",
    "\n",
    "def dense_block(units, dropout=0.2, activation='relu', name='fc1'):\n",
    "\n",
    "    def layer_wrapper(inp):\n",
    "        x = Dense(units, name=name)(inp)\n",
    "        x = BatchNormalization(name='{}_bn'.format(name))(x)\n",
    "        x = Activation(activation, name='{}_act'.format(name))(x)\n",
    "        x = Dropout(dropout, name='{}_dropout'.format(name))(x)\n",
    "        return x\n",
    "\n",
    "    return layer_wrapper\n",
    "        \n",
    "\n",
    "def VGG16_BN(input_tensor=None, input_shape=None, classes=1000, conv_dropout=0.1, dropout=0.3, activation='relu'):\n",
    "    \"\"\"Instantiates the VGG16 architecture with Batch Normalization\n",
    "    # Arguments\n",
    "        input_tensor: Keras tensor (i.e. output of `layers.Input()`) to use as image input for the model.\n",
    "        input_shape: shape tuple\n",
    "        classes: optional number of classes to classify images\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    \"\"\"\n",
    "    img_input = Input(shape=input_shape) if input_tensor is None else (\n",
    "        Input(tensor=input_tensor, shape=input_shape) if not K.is_keras_tensor(input_tensor) else input_tensor\n",
    "    )\n",
    "\n",
    "    # Block 1\n",
    "    x = conv_block(32, dropout=conv_dropout, activation=activation, block=1, layer=1)(img_input)\n",
    "    x = conv_block(32, dropout=conv_dropout, activation=activation, block=1, layer=2)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = conv_block(64, dropout=conv_dropout, activation=activation, block=2, layer=1)(x)\n",
    "    x = conv_block(64, dropout=conv_dropout, activation=activation, block=2, layer=2)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = conv_block(128, dropout=conv_dropout, activation=activation, block=3, layer=1)(x)\n",
    "    x = conv_block(128, dropout=conv_dropout, activation=activation, block=3, layer=2)(x)\n",
    "    x = conv_block(128, dropout=conv_dropout, activation=activation, block=3, layer=3)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = conv_block(256, dropout=conv_dropout, activation=activation, block=4, layer=1)(x)\n",
    "    x = conv_block(256, dropout=conv_dropout, activation=activation, block=4, layer=2)(x)\n",
    "    x = conv_block(256, dropout=conv_dropout, activation=activation, block=4, layer=3)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = conv_block(256, dropout=conv_dropout, activation=activation, block=5, layer=1)(x)\n",
    "    x = conv_block(256, dropout=conv_dropout, activation=activation, block=5, layer=2)(x)\n",
    "    x = conv_block(256, dropout=conv_dropout, activation=activation, block=5, layer=3)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    # Flatten\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # FC Layers\n",
    "    x = dense_block(512, dropout=dropout, activation=activation, name='fc1')(x)\n",
    "    x = dense_block(512, dropout=dropout, activation=activation, name='fc2')(x)\n",
    "    \n",
    "    # Classification block    \n",
    "    x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    # Ensure that the model takes into account any potential predecessors of `input_tensor`.\n",
    "    inputs = get_source_inputs(input_tensor) if input_tensor is not None else img_input\n",
    "\n",
    "    # Create model.\n",
    "    return Model(inputs, x, name='vgg16_bn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "y = Conv2D(filters=filters,kernel_size=kernel_size,activation='relu')(inputs)\n",
    "y = MaxPooling2D()(y)\n",
    "y = Conv2D(filters=filters,kernel_size=kernel_size,activation='relu')(y)\n",
    "y = MaxPooling2D()(y)\n",
    "y = Conv2D(filters=filters,kernel_size=kernel_size,activation='relu')(y)\n",
    " \n",
    "y = Flatten()(y)\n",
    " \n",
    "y = Dropout(dropout)(y)\n",
    "outputs = Dense(num_labels, activation='softmax')(y)\n",
    "\n",
    " \n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    " \n",
    "#model =VGG16_BN(input_tensor=None, input_shape=x_train.shape[1:], classes=10, conv_dropout=0.1, dropout=0.3, activation='relu')\n",
    " \n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "from adam_or import Aadam\n",
    "from AdamT import AdamT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw=model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 1.6151 - accuracy: 0.4098 - val_loss: 1.2834 - val_accuracy: 0.5333\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.2707 - accuracy: 0.5507 - val_loss: 1.3967 - val_accuracy: 0.5158\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.1239 - accuracy: 0.6062 - val_loss: 1.0745 - val_accuracy: 0.6288\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.0360 - accuracy: 0.6375 - val_loss: 1.0399 - val_accuracy: 0.6453\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.9598 - accuracy: 0.6657 - val_loss: 0.9546 - val_accuracy: 0.6638\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.9034 - accuracy: 0.6832 - val_loss: 0.9024 - val_accuracy: 0.6943\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.8660 - accuracy: 0.6969 - val_loss: 0.8762 - val_accuracy: 0.6938\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.8277 - accuracy: 0.7102 - val_loss: 0.9114 - val_accuracy: 0.6788\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.8018 - accuracy: 0.7171 - val_loss: 0.8227 - val_accuracy: 0.7149\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.7685 - accuracy: 0.7331 - val_loss: 0.8464 - val_accuracy: 0.7114\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.7434 - accuracy: 0.7405 - val_loss: 0.8248 - val_accuracy: 0.7164\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.7180 - accuracy: 0.7468 - val_loss: 0.8947 - val_accuracy: 0.6848\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.7012 - accuracy: 0.7540 - val_loss: 0.8155 - val_accuracy: 0.7199\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.6771 - accuracy: 0.7617 - val_loss: 0.8251 - val_accuracy: 0.7249\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.6671 - accuracy: 0.7634 - val_loss: 0.7810 - val_accuracy: 0.7389\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.6463 - accuracy: 0.7734 - val_loss: 0.7854 - val_accuracy: 0.7389\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.6371 - accuracy: 0.7767 - val_loss: 0.7937 - val_accuracy: 0.7354\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.6217 - accuracy: 0.7802 - val_loss: 0.8129 - val_accuracy: 0.7284\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.6113 - accuracy: 0.7832 - val_loss: 0.8673 - val_accuracy: 0.7209\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.5990 - accuracy: 0.7884 - val_loss: 0.8548 - val_accuracy: 0.7129\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.5864 - accuracy: 0.7922 - val_loss: 0.7869 - val_accuracy: 0.7289\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.5785 - accuracy: 0.7949 - val_loss: 0.7799 - val_accuracy: 0.7344\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.5689 - accuracy: 0.7992 - val_loss: 0.8258 - val_accuracy: 0.7379\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.5533 - accuracy: 0.8040 - val_loss: 0.8260 - val_accuracy: 0.7269\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.5542 - accuracy: 0.8007 - val_loss: 0.8070 - val_accuracy: 0.7274\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.5426 - accuracy: 0.8082 - val_loss: 0.8458 - val_accuracy: 0.7289\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.5358 - accuracy: 0.8103 - val_loss: 0.8167 - val_accuracy: 0.7299\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.5255 - accuracy: 0.8140 - val_loss: 0.8604 - val_accuracy: 0.7224\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.5200 - accuracy: 0.8149 - val_loss: 0.8363 - val_accuracy: 0.7279\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.5060 - accuracy: 0.8191 - val_loss: 0.8446 - val_accuracy: 0.7279\n"
     ]
    }
   ],
   "source": [
    "ep=30\n",
    "lra=[5e-3,1e-3,5e-4,1e-4]\n",
    "optimizer = AdamT()\n",
    "\n",
    "\n",
    "weights_dict = {}\n",
    "\n",
    "weight_callback = tf.keras.callbacks.LambdaCallback \\\n",
    "( on_epoch_end=lambda epoch, logs: weights_dict.update({epoch:model.get_weights()}))\n",
    "\n",
    "\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "\n",
    "\n",
    "hb1=model.fit(x_train,y_train, epochs=ep, validation_data=(x_test, y_test), callbacks = [weight_callback  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fw=model.get_weights()\n",
    "# model2=model\n",
    "\n",
    "# model2.set_weights(fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.5703 - accuracy: 0.4261 - val_loss: 1.3254 - val_accuracy: 0.5153\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 1.2340 - accuracy: 0.5619 - val_loss: 1.1358 - val_accuracy: 0.5878\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 1.1006 - accuracy: 0.6122 - val_loss: 1.0175 - val_accuracy: 0.6383\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 1.0167 - accuracy: 0.6462 - val_loss: 0.9984 - val_accuracy: 0.6578\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.9541 - accuracy: 0.6657 - val_loss: 0.9073 - val_accuracy: 0.6778\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.9049 - accuracy: 0.6847 - val_loss: 0.9032 - val_accuracy: 0.6758\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.8666 - accuracy: 0.6971 - val_loss: 0.9213 - val_accuracy: 0.6743\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.8367 - accuracy: 0.7075 - val_loss: 0.8678 - val_accuracy: 0.6943\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.8137 - accuracy: 0.7149 - val_loss: 0.8366 - val_accuracy: 0.7059\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.7864 - accuracy: 0.7240 - val_loss: 0.8318 - val_accuracy: 0.7189\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.7642 - accuracy: 0.7328 - val_loss: 0.8034 - val_accuracy: 0.7224\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.7443 - accuracy: 0.7397 - val_loss: 0.8292 - val_accuracy: 0.7284\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.7272 - accuracy: 0.7468 - val_loss: 0.8245 - val_accuracy: 0.7159\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.7067 - accuracy: 0.7525 - val_loss: 0.7858 - val_accuracy: 0.7279\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.6932 - accuracy: 0.7571 - val_loss: 0.8193 - val_accuracy: 0.7204\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.6805 - accuracy: 0.7631 - val_loss: 0.7912 - val_accuracy: 0.7369\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.6640 - accuracy: 0.7669 - val_loss: 0.7841 - val_accuracy: 0.7404\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.6494 - accuracy: 0.7727 - val_loss: 0.8012 - val_accuracy: 0.7344\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.6433 - accuracy: 0.7736 - val_loss: 0.7848 - val_accuracy: 0.7404\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.6278 - accuracy: 0.7774 - val_loss: 0.8299 - val_accuracy: 0.7294\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 0.6159 - accuracy: 0.7829 - val_loss: 0.8086 - val_accuracy: 0.7364\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 0.6053 - accuracy: 0.7875 - val_loss: 0.7911 - val_accuracy: 0.7404\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 0.5971 - accuracy: 0.7898 - val_loss: 0.8057 - val_accuracy: 0.7299\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 0.5866 - accuracy: 0.7938 - val_loss: 0.8130 - val_accuracy: 0.7304\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.5780 - accuracy: 0.7947 - val_loss: 0.7846 - val_accuracy: 0.7454\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.5730 - accuracy: 0.7981 - val_loss: 0.7968 - val_accuracy: 0.7324\n",
      "Epoch 27/30\n",
      "44448/50000 [=========================>....] - ETA: 0s - loss: 0.5608 - accuracy: 0.8031"
     ]
    }
   ],
   "source": [
    "model2=  Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = Aadam()\n",
    "model2.set_weights(fw)\n",
    "\n",
    "weights_dict = {}\n",
    "\n",
    "weight_callback = tf.keras.callbacks.LambdaCallback \\\n",
    "( on_epoch_end=lambda epoch, logs: weights_dict.update({epoch:model.get_weights()}))\n",
    "\n",
    "\n",
    "model2.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "\n",
    "\n",
    "hb2=model2.fit(x_train,y_train, epochs=ep, validation_data=(x_test, y_test), callbacks = [weight_callback  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1=hb1.history['accuracy']\n",
    "h2=hb2.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h1)\n",
    "plt.plot(h2)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['AdamT', 'Adam'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vh1=hb1.history['val_accuracy']\n",
    "vh2=hb2.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vh1)\n",
    "plt.plot(vh2)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['AdamT', 'Adam'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Bdeep] *",
   "language": "python",
   "name": "conda-env-Bdeep-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
